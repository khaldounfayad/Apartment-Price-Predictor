# -*- coding: utf-8 -*-
"""Lab4_miki.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tEoWwPBggQX85cSiZ5Jbk5X9xO0rObNr
"""

#loading in necessary toolboxes
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.inspection import permutation_importance
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import linear_model
from sklearn.metrics import r2_score
from sklearn.pipeline import make_pipeline
from scipy.stats import skew
from sklearn.linear_model import LinearRegression, Ridge, LassoCV
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import SGDRegressor
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import log_loss, accuracy_score
from sklearn import linear_model
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.svm import SVR
from sklearn.metrics import mean_absolute_error
from xgboost.sklearn import XGBRegressor
from sklearn.model_selection import RepeatedKFold
from numpy import absolute
#import graphviz
import xgboost as xgb

"""Loading data"""

#loading data, it is split into 3 files each corresponding to the month it was collected in
df_august = pd.read_csv('https://raw.githubusercontent.com/WitoldSurdej/PFML/master/apartments_pl_2023_08.csv')
df_september = pd.read_csv('https://raw.githubusercontent.com/WitoldSurdej/PFML/master/apartments_pl_2023_09.csv')
df_october = pd.read_csv('https://raw.githubusercontent.com/WitoldSurdej/PFML/master/apartments_pl_2023_10.csv')

#displaying data
df_august.head()

df_september.head()

df_october.head()

#showing the size of each dataset
print(df_august.shape)
print(df_september.shape)
print(df_october.shape)

"""Concatenating Data"""

#labeling the data from each dataset
df_august['Month'] = 0
df_september['Month'] = 1
df_october['Month'] = 2

#combining datasets into 1
frames = [df_august, df_september, df_october]
#creating a dataframe
df = pd.concat(frames)

"""Data processing"""

# Shape of dataframe
df.shape

# Checking for missing values
df.isna().sum()

#creating temporary data frame
df_temp=df
# Dropping id and columns which have a very high number of missing values, being impossible to apply techniques such as imputation
df.drop(['id','type', 'floor', 'buildYear', 'floorCount', 'condition', 'buildingMaterial'], axis=1, inplace=True)

"""Definition:
Data imputation is a process used in data analysis and preprocessing to fill in missing or incomplete data with estimated or substituted values. Missing data can be a common issue when dealing with real-world datasets, and imputation methods are used to handle these missing values effectively. Data imputation is essential because many statistical and machine learning algorithms may not work properly with missing data, and imputing values allows you to preserve as much information as possible.
"""

# Dropping rows which contain missing values
df_clean = df.dropna()

# Dropping duplicates if any
df_clean = df_clean.drop_duplicates().reset_index(drop=True)

#displaying cleared data
df_clean.head(5)

#showing data size after cleaning
df_clean.shape

"""Selecting Numerical and Categorical Columns"""

#dropping categorical data
cat_cols = df_clean.select_dtypes(['object']).columns
df_cats = df_clean[cat_cols].reset_index(drop=True)

"""Data Split"""

#splitting data into train and test with proportions 70/30
X1 = df_clean.loc[:, df_clean.columns != 'price']
y1 = df_clean['price'].values

X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.3, random_state = 42)

#displaying shape of the split data
print(X1.shape)
print(y1.shape)
print(X1_train.shape)
print(X1_test.shape)

"""Data visualisation"""

num_cols = X1.select_dtypes([np.number]).columns
df_nums = X1[num_cols].reset_index(drop=True)

"""Box Plot"""

features = num_cols.to_list()
plt.figure(figsize=(15,5))
for i in range(0, len(features)):
    plt.subplot(2, 7, i + 1)
    sns.boxplot(y = X1[features[i]], color = 'magenta', orient = 'v')
    plt.tight_layout()

"""Histogram plot"""

features = num_cols.to_list()
plt.figure(figsize = (20, 10))
for i in range(0, len(features)):
    plt.subplot(5, 3, i+1)
    sns.histplot(x = X1[features[i]], kde = True, color = 'green')
    plt.tight_layout()

plt.figure(figsize = (15, 8))
sns.heatmap(df_clean.corr(), cmap = 'Blues', annot = True, fmt = '.2f')
plt.xticks(rotation=45);

num_cols = X1_train.select_dtypes([np.number]).columns
df_nums_train = X1_train[num_cols].reset_index(drop=True)
num_cols = X1_test.select_dtypes([np.number]).columns
df_nums_test = X1_test[num_cols].reset_index(drop=True)

clf=tree.DecisionTreeClassifier().fit(df_nums_train,y1_train)

print(clf.score(df_nums_train,y1_train))
print(clf.score(df_nums_test,y1_test))